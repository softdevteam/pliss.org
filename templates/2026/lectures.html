<%include file="header.inc" args="title='Lectures'"/>
<!-- Main -->
<section id="main" class="wrapper">
  <div class="container">
    <header class="major special"><h2>Lectures</h2><p></p></header>
    <div class="content">

      <div id="clebsch" style="margin-top: -6em; position: absolute"></div>
      <header>
	<h4>Implement a Language at this Language Implementation Thing</h4>
        <p>Sylvan Clebsch</p>
      </header>
      <p>
      We wanted to build more experimental languages, so we built some
      experimental tools! Let's use them! We'll use Trieste (a tree-rewriting
      system) to target VBCC (an IR implemented in Trieste) to generate
      bytecode for VBCI (a data-race free concurrent infinite-register
      interpreter). After these talks, you'll know enough about C++ and these
      tools to implement your own language.
      </p>

      <div id="flatt" style="margin-top: -6em; position: absolute"></div>
      <header>
	<h4>Metaprogramming in Rhombus</h4>
        <p>Matthew Flatt</p>
      </header>
      <p>
      This tutorial is about syntax and macros in Rhombus. We won’t assume that
      participants have used Rhombus before, but we also won’t dwell much on
      the everyday-programming part of the language, since we expect that
      participants can pick it up easily as we go. Instead, we’ll get into the
      nuts and bolts of Rhombus’s approach to parsing, syntactic extension, and
      language creation.
      </p>

      <div id="hosking" style="margin-top: -6em; position: absolute"></div>
      <header>
        <h4>Memory management for concurrent Rust data structures</h4>
        <p>Tony Hosking</p>
      </header>
      <p>
      </p>

      <header>
      <h4>Transactions and persistence for WebAssembly"</h4>
        <p>Tony Hosking</p>
      </header>

      <div id="ryu" style="margin-top: -6em; position: absolute"></div>
      <header>
	<h4>Mechanized Specifications Adopted by Real-World Programming Languages</h4>
        <p>Sukyoung Ryu</p>
      </header>
      <p>
      Real-world programming languages have multiple implementations and
      continue to evolve, often resulting in inconsistencies between
      implementations. To mitigate this issue, language mechanization
      frameworks have been proposed, which guarantee the same behavior between
      the executable semantics described in a mechanized specification and
      tools such as interpreters automatically generated from the mechanized
      specification. Recently, three real-world programming languages have
      adopted mechanized specifications. In 2022, the TC39 committee decided to
      integrate ESMeta into the CI systems of the JavaScript language
      specification and its official test suite. In 2025, the WebAssembly
      (Wasm) Community Group voted to adopt SpecTec for authoring future
      versions of the Wasm specification. The P4 Language Design Working Group
      considers adopting P4-SpecTec for authoring the P4 specification. For
      each adoption case, we share the challenges faced by the language
      community, how the mechanization framework addressed them, and how the
      language community’s governance helped promote adoption. We discuss
      programming languages promising for mechanization, various mechanization
      frameworks, and frequently asked questions regarding the adoption of
      mechanized specifications into new programming languages.
      </p>

      <div id="thakur" style="margin-top: -6em; position: absolute"></div>
      <header>
	<h4>Fixing the see-saw: Enabling Precise Optimizations in JIT Compilers, Efficiently</h4>
        <p>Manas Thakur</p>
      </header>
      <p>
      Just-in-time (JIT) compilers offer novel ways to optimize programs based
      on their execution profile and have found significant usage in languages
      with managed runtimes. However, as JIT compilation directly affects the
      execution time of a program, precision-enhancement techniques from the
      static-analysis world seldom find way into these otherwise powerful
      systems. Under this backdrop, we would first understand how modern JIT
      compilers optimize code, using examples of program analysis aimed at
      enabling stack allocation of heap objects in Java. We would then
      understand techniques to not only allocate a large number of objects on
      stack (leading to reduced garbage collection and improved performance),
      but to also handle challenges posed by possible dynamism in real-world
      Java Virtual Machines. In particular, we would talk about AOT-analysis
      guided optimistic stack allocation, as well as the usage of speculative
      JIT information in improving the precision of statically computed
      results. All parts of the story would be bound by the over-arching goal
      of maintaining precision and efficiency, while being sound, during
      program execution.
      </p>

      <div id="wrigstad" style="margin-top: -6em; position: absolute"></div>
      <header>
	<h4>Retrofitting Data-Race Freedom — Or: I'll Try Anything Twice</h4>
        <p>Tobias Wrigstad</p>
      </header>
      <p>
      No two train wrecks are alike? I will be reporting on two attempts at
      retrofitting data-race freedom to two different programming languages —
      Python and Java — that both have existed for more than 30 years, and are
      the result of tons on pragmatic design decisions, both at the language
      level and at the implementation level. The lecture encompasses language
      design, implementation, pragmatism, as well as lessons learned working
      with both languages and comparisons of two different approaches to
      achieving backwards compatibility. 
      </p>

    </div>
  </div>
</section>

<%include file="footer.inc" />
